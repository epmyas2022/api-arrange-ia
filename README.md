# API Arrange IA

## üìã Descripci√≥n

API REST que permite interactuar con m√∫ltiples modelos de lenguaje IA (Cerebras, Groq, OpenRouter) mediante un sistema de balanceo de carga round-robin. La API mantiene el contexto de la conversaci√≥n mediante cursores codificados y soporta streaming de respuestas.

## üöÄ Caracter√≠sticas

- **M√∫ltiples proveedores de IA**: Integraci√≥n con Cerebras, Groq y OpenRouter
- **Balanceo de carga**: Rotaci√≥n autom√°tica entre modelos disponibles
- **Gesti√≥n de contexto**: Sistema de cursores para mantener el historial de conversaci√≥n
- **Streaming**: Respuestas en tiempo real mediante streaming
- **Prompts personalizados**: Sistema de prompts modulares
- **CORS habilitado**: Listo para uso desde frontends

## üõ†Ô∏è Tecnolog√≠as

- **NestJS** - Framework Node.js
- **TypeScript** - Tipado est√°tico
- **pnpm** - Gestor de paquetes
- **SDKs**:
  - @cerebras/cerebras_cloud_sdk
  - groq-sdk
  - @openrouter/sdk
  - openai

## üì¶ Instalaci√≥n

```bash
# Instalar dependencias
pnpm install

# Configurar variables de entorno
cp .env.example .env
```

## ‚öôÔ∏è Configuraci√≥n

Crea un archivo `.env` con las siguientes variables:

```env
# API Keys de los proveedores
CEREBRAS_API_KEY=your_cerebras_api_key
GROQ_API_KEY=your_groq_api_key
OPENROUTER_API_KEY=your_openrouter_api_key

# Configuraci√≥n del servidor (opcional)
PORT=4000
```

## üéØ Uso

### Iniciar el servidor

```bash
# Desarrollo
pnpm start:dev

# Producci√≥n
pnpm build
pnpm start:prod
```

El servidor estar√° disponible en `http://localhost:4000`

### Endpoint principal

**POST** `/`

Env√≠a un mensaje y recibe una respuesta del modelo de IA.

#### Request Body

```json
{
  "message": "Tu mensaje aqu√≠",
  "cursor": "cursor_opcional_para_continuar_conversacion"
}
```

#### Response

```json
{
  "ok": "done",
  "response": "Respuesta del modelo de IA",
  "cursor": "base64_encoded_conversation_history"
}
```

#### Ejemplo con cURL

```bash
# Primera interacci√≥n
curl -X POST http://localhost:4000 \
  -H "Content-Type: application/json" \
  -d '{"message": "Hola, ¬øc√≥mo est√°s?"}'

# Continuar conversaci√≥n usando el cursor
curl -X POST http://localhost:4000 \
  -H "Content-Type: application/json" \
  -d '{
    "message": "Cu√©ntame m√°s sobre eso",
    "cursor": "eyJyb2xlIjoic3lz..."
  }'
```

## üîÑ Sistema de Rotaci√≥n de Modelos

La API implementa un sistema round-robin que alterna autom√°ticamente entre los modelos disponibles:

1. **Cerebras** ‚Üí 2. **Groq** ‚Üí 3. **OpenRouter** ‚Üí (vuelta a Cerebras)

Cada petici√≥n usa el siguiente modelo en la secuencia, distribuyendo la carga entre proveedores.

## üíæ Sistema de Cursores

El cursor codifica en base64 el historial completo de la conversaci√≥n:

```typescript
// Estructura del cursor decodificado
[
  { role: "system", content: "Prompt del sistema" },
  { role: "user", content: "Primer mensaje" },
  { role: "assistant", content: "Primera respuesta" },
  { role: "user", content: "Segundo mensaje" },
  { role: "assistant", content: "Segunda respuesta" }
]
```

## üîß Scripts Disponibles

```bash
pnpm start          # Inicia en modo producci√≥n
pnpm start:dev      # Inicia con hot-reload
pnpm start:debug    # Inicia con debugger
pnpm build          # Compila el proyecto
pnpm format         # Formatea c√≥digo con Prettier
pnpm lint           # Ejecuta ESLint
```

## üìù Personalizaci√≥n de Prompts

Los prompts del sistema se gestionan en `src/prompts/`:

1. Crea un archivo markdown en `src/prompts/`
2. Usa `loadPrompt('nombre-archivo')` para cargarlo
3. El prompt se incluir√° autom√°ticamente en el contexto

**Nota**: Aseg√∫rate de configurar correctamente las API keys antes de usar la aplicaci√≥n.
